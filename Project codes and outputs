 import os
 import pandas as pd
 import numpy as np
 import matplotlib.pyplot as plt
 import seaborn as sns

 # BASICS
 print(os.listdir('/content/drive/MyDrive/IBM'))
 df = pd.read_csv('/content/drive/MyDrive/IBM/crop_production.csv')
 print('First few rows of the dataset')
 print(df.head())
 print("Dataset Information:")
 print(df.info())
 print("Summary Statistics:")
 print(df.describe())

 # CLEANING
 print(os.listdir('/content/drive/MyDrive/IBM'))
 # Loading the dataset
 df = pd.read_csv('/content/drive/MyDrive/IBM/crop_production.csv')
 # Displaying initial summary statistics
 print("Summary Statistics before cleaning:")
 print(df.describe())
 # 1. Dropping rows with any NaN values in 'Value' column (or any other column if necessary)
 df_clean = df.dropna(subset=['Value'])
 # 2. Dropping columns with all NaN values (e.g., 'Flag Codes')
 df_clean = df_clean.dropna(axis=1, how='all')
 # 3. Removing duplicate rows if there are any
 df_clean = df_clean.drop_duplicates()
 # 4. Checking for any remaining NaN values in the dataset
 print("Remaining NaN values after cleaning:")
 print(df_clean.isna().sum())
 # Cleaned summary statistics
 print("Summary Statistics after cleaning:")
 print(df_clean.describe())
 print("Data cleaning completed and saved as 'cleaned_crop_production.csv'.")
 df_clean.to_csv('/content/drive/MyDrive/IBM/cleaned_crop_production.csv', index=False)

 # NUMPY (SD, MEAN, MODE)
 df_clean = pd.read_csv('/content/drive/MyDrive/IBM/cleaned_crop_production.csv')
 # Conversion DataFrame to NumPy array
 data_array = df_clean.to_numpy()
 values = data_array[:, 7]
 mean_value = np.mean(values)
 median_value = np.median(values)
 std_deviation = np.std(values)
 print(f"Mean: {mean_value}")
 print(f"Median: {median_value}")
 print(f"Standard Deviation: {std_deviation}")
 normalized_values = (values - np.min(values)) / (np.max(values) - np.min(values))
 df_clean['Normalized_Value'] = normalized_values
 # Saving the updated DataFrame with normalized values
 df_clean.to_csv('/content/drive/MyDrive/IBM/cleaned_and_normalized_crop_production.csv', index=False)
 print("Data normalization completed and saved as 'cleaned_and_normalized_crop_production.csv'.")

 # FILTERING
 df = pd.read_csv('/content/drive/MyDrive/IBM/crop_production.csv')
 # Filter data for specific crops and years
 crops = ['WHEAT', 'MAIZE', 'RICE', 'SOYBEANS']
 filtered_df = df[(df['SUBJECT'].isin(crops)) & (df['TIME'].between(2010, 2016))]
 # Drop rows with any NaN values in 'Value' column
 filtered_df = filtered_df.dropna(subset=['Value'])
 # Drop columns with all NaN values
 filtered_df = filtered_df.dropna(axis=1, how='all')
 # Remove duplicate rows
 filtered_df = filtered_df.drop_duplicates()
 # Save the filtered dataset to a new CSV file (optional)
 filtered_df.to_csv('/content/drive/MyDrive/IBM/filtered_crop_production.csv', index=False)
 print("Data preparation completed.")

 # GRAPHS OF MATPLOT AND SEABORN
 print(filtered_df.describe())
 custom_palette = sns.color_palette("Greens", as_cmap=True)
 # Trend Analysis: Visualize crop yields over the years
 plt.figure(figsize=(10, 6))
 sns.lineplot(data=filtered_df, x='TIME', y='Value', hue='SUBJECT', palette='Greens')
 plt.title('Crop Yields Over Time', fontsize=16)
 plt.xlabel('Year', fontsize=14)
 plt.ylabel('Yield (TONNE_HA)', fontsize=14)
 plt.legend(title='Crop', title_fontsize='13', fontsize='11')
 plt.xticks(fontsize=12)
 l i k (f i )
plt.yticks(fontsize=12)
 plt.grid(True, linestyle='--', alpha=0.7)
 plt.show()
 # Compute correlation matrix only on numeric columns
 plt.figure(figsize=(10, 6))
 numeric_df = filtered_df.select_dtypes(include=[np.number])
 correlation_matrix = numeric_df.corr()
 sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
 plt.title('Correlation Matrix')
 plt.show()
 avg_yields = df.groupby('SUBJECT')['Value'].mean()
 avg_yields.plot(kind='bar')
 plt.xlabel('Crop')
 plt.ylabel('Average Yield (TONNE_HA)')
 plt.title('Average Crop Yield by Type')
 plt.show()
 pivot_table = df.pivot_table(values='Value', index='TIME', columns='LOCATION')
 sns.heatmap(pivot_table, cmap='YlGnBu')
 plt.xlabel('Location')
 plt.ylabel('Year')
 plt.title('Heatmap of Crop Yields by Year and Location')
 plt.show()
 sns.boxplot(x='TIME', y='Value', data=df)
 plt.xlabel('Year')
 plt.ylabel('Crop Yield (TONNE_HA)')
 plt.title('Box Plot of Crop Yields by Year')
 plt.xticks(rotation=45)
 plt.show()

 # MACHINE LEARNING ALGORITHMS
 import pandas as pd
 import numpy as np
 import matplotlib.pyplot as plt
 import seaborn as sns
 from sklearn.model_selection import train_test_split, GridSearchCV
 from sklearn.ensemble import RandomForestRegressor
 from sklearn.metrics import mean_squared_error, r2_score
 # Load the dataset
 df = pd.read_csv('/content/drive/MyDrive/IBM/filtered_crop_production.csv')
 # Prepare data for machine learning
 X = df[['TIME', 'LOCATION']].copy()
 y = df['Value']
 # Convert categorical data to numeric
 X = pd.get_dummies(X, columns=['LOCATION'], drop_first=True)
 # Split the data into training and testing sets
 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
 # Hyperparameter tuning for Random Forest Regressor
 param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'bootstrap': [True, False]
 }
 rf = RandomForestRegressor(random_state=42)
 grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)
 grid_search.fit(X_train, y_train)
 # Best parameters and model
 best_params = grid_search.best_params_
 print(f"Best parameters: {best_params}")
 best_rf = grid_search.best_estimator_
 # Predictions
 y_pred_rf = best_rf.predict(X_test)
 # Evaluate the model
 mse_rf = mean_squared_error(y_test, y_pred_rf)
 r2_rf = r2_score(y_test, y_pred_rf)
 print(f"Random Forest Regression - Mean Squared Error: {mse_rf}")
print(f"Random Forest Regression - R^2 Score: {r2_rf}")
 # Feature Importance
 importances = best_rf.feature_importances_
 features = X.columns
 indices = np.argsort(importances)[::-1]
 # Print the feature ranking
 print("Feature ranking:")
 for f in range(X.shape[1]):
    print(f"{f + 1}. feature {features[indices[f]]} ({importances[indices[f]]})")
 # Plot the feature importances
 plt.figure(figsize=(10, 6))
 plt.title("Feature Importances")
 plt.bar(range(X.shape[1]), importances[indices], align="center")
 plt.xticks(range(X.shape[1]), features[indices], rotation=90)
 plt.xlim([-1, X.shape[1]])
 plt.show()
 # Save the predictions
 df['Predicted_Value'] = best_rf.predict(X)
 df.to_csv('/content/drive/MyDrive/IBM/predicted_crop_production.csv', index=False)
 print("Predictions saved to 'predicted_crop_production.csv'.")

OUTPUTS
['IBM.ipynb', 'crop_production.csv', 'cleaned_crop_production.csv', 'cleaned_and_normalized_crop_production.csv', 'filtered_
 First few rows of the dataset
   index LOCATION  INDICATOR SUBJECT   MEASURE FREQUENCY  TIME     Value  \
 0      0      AUS  CROPYIELD    RICE  TONNE_HA         A  1990  8.314607   
1      1      AUS  CROPYIELD    RICE  TONNE_HA         A  1991  8.394737   
2      2      AUS  CROPYIELD    RICE  TONNE_HA         A  1992  8.094340   
3      3      AUS  CROPYIELD    RICE  TONNE_HA         A  1993  8.336000   
4      4      AUS  CROPYIELD    RICE  TONNE_HA         A  1994  8.537815   
   Flag Codes  
0         NaN  
1         NaN  
2         NaN  
3         NaN  
4         NaN  
Dataset Information:
 <class 'pandas.core.frame.DataFrame'>
 RangeIndex: 20566 entries, 0 to 20565
 Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  ---  ------      --------------  -----  
 0   index       20566 non-null  int64  
 1   LOCATION    20566 non-null  object 
 2   INDICATOR   20566 non-null  object 
 3   SUBJECT     20566 non-null  object 
 4   MEASURE     20566 non-null  object 
 5   FREQUENCY   20566 non-null  object 
 6   TIME        20566 non-null  int64  
 7   Value       20566 non-null  float64
 8   Flag Codes  0 non-null      float64
 dtypes: float64(2), int64(2), object(5)
 memory usage: 1.4+ MB
 None
 Summary Statistics:
              index          TIME         Value  Flag Codes
 count  20566.000000  20566.000000  2.056600e+04         0.0
 mean   10282.500000   2007.591170  1.249281e+04         NaN
 std     5937.037154     10.369489  5.960529e+04         NaN
 min        0.000000   1970.000000  0.000000e+00         NaN
 25%     5141.250000   1999.000000  1.961877e+00         NaN
 50%    10282.500000   2008.000000  2.560970e+01         NaN
 75%    15423.750000   2017.000000  1.563000e+03         NaN
 max    20565.000000   2025.000000  1.146044e+06         NaN
 ['IBM.ipynb', 'crop_production.csv', 'cleaned_crop_production.csv', 'cleaned_and_normalized_crop_production.csv', 'filtered_
 Summary Statistics before cleaning:
              index          TIME         Value  Flag Codes
 count  20566.000000  20566.000000  2.056600e+04         0.0
 mean   10282.500000   2007.591170  1.249281e+04         NaN
 std     5937.037154     10.369489  5.960529e+04         NaN
 min        0.000000   1970.000000  0.000000e+00         NaN
 25%     5141.250000   1999.000000  1.961877e+00         NaN
 50%    10282.500000   2008.000000  2.560970e+01         NaN
 75%    15423.750000   2017.000000  1.563000e+03         NaN
 max    20565.000000   2025.000000  1.146044e+06         NaN
 Remaining NaN values after cleaning:
 index        0
 LOCATION     0
 INDICATOR    0
 SUBJECT      0
 MEASURE      0
 FREQUENCY    0
 TIME         0
 Value        0
 dtype: int64
 Summary Statistics after cleaning:
              index          TIME         Value
 count  20566.000000  20566.000000  2.056600e+04
 mean   10282.500000   2007.591170  1.249281e+04
 std     5937.037154     10.369489  5.960529e+04
 min        0.000000   1970.000000  0.000000e+00
 25%     5141.250000   1999.000000  1.961877e+00
 50%    10282.500000   2008.000000  2.560970e+01
 75%    15423.750000   2017.000000  1.563000e+03
 max    20565.000000   2025.000000  1.146044e+06
 Data cleaning completed and saved as 'cleaned_crop_production.csv'.
 Mean: 12492.807578644237
 Median: 25.609697505
 Standard Deviation: 59603.84253353299
 Data normalization completed and saved as 'cleaned_and_normalized_crop_production.csv'.
 Data preparation completed.
              index         TIME         Value
 count   3024.000000  3024.000000  3.024000e+03
 mean    8539.143519  2013.000000  1.680376e+04
 std     5620.848464     2.000331  7.515412e+04
 min       20.000000  2010.000000  0.000000e+00
 25%     3864.500000  2011.000000  3.103485e+00
 50%     7725.000000  2013.000000  8.772555e+01
 75%    12756.500000  2015.000000  2.851500e+03
 max    20525.000000  2016.000000  1.031399e+06

